{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc2576ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df41678c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./train.csv')\n",
    "df_test = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cc3a79",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "997aefcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Both datasets have the same columns (excluding target)\n",
      "\n",
      "Comparing data types for 25 common columns:\n",
      "------------------------------------------------------------\n",
      "✓ age                                 | Train: int64      | Test: int64\n",
      "✓ alcohol_consumption_per_week        | Train: int64      | Test: int64\n",
      "✓ bmi                                 | Train: float64    | Test: float64\n",
      "✓ cardiovascular_history              | Train: int64      | Test: int64\n",
      "✓ cholesterol_total                   | Train: int64      | Test: int64\n",
      "✓ diastolic_bp                        | Train: int64      | Test: int64\n",
      "✓ diet_score                          | Train: float64    | Test: float64\n",
      "✓ education_level                     | Train: object     | Test: object\n",
      "✓ employment_status                   | Train: object     | Test: object\n",
      "✓ ethnicity                           | Train: object     | Test: object\n",
      "✓ family_history_diabetes             | Train: int64      | Test: int64\n",
      "✓ gender                              | Train: object     | Test: object\n",
      "✓ hdl_cholesterol                     | Train: int64      | Test: int64\n",
      "✓ heart_rate                          | Train: int64      | Test: int64\n",
      "✓ hypertension_history                | Train: int64      | Test: int64\n",
      "✓ id                                  | Train: int64      | Test: int64\n",
      "✓ income_level                        | Train: object     | Test: object\n",
      "✓ ldl_cholesterol                     | Train: int64      | Test: int64\n",
      "✓ physical_activity_minutes_per_week  | Train: int64      | Test: int64\n",
      "✓ screen_time_hours_per_day           | Train: float64    | Test: float64\n",
      "✓ sleep_hours_per_day                 | Train: float64    | Test: float64\n",
      "✓ smoking_status                      | Train: object     | Test: object\n",
      "✓ systolic_bp                         | Train: int64      | Test: int64\n",
      "✓ triglycerides                       | Train: int64      | Test: int64\n",
      "✓ waist_to_hip_ratio                  | Train: float64    | Test: float64\n"
     ]
    }
   ],
   "source": [
    "# Get common columns\n",
    "common_cols = set(df_train.columns) & set(df_test.columns)\n",
    "\n",
    "# Check if they have the same columns (excluding target column)\n",
    "train_cols = set(df_train.columns) - {'diagnosed_diabetes'}\n",
    "test_cols = set(df_test.columns)\n",
    "\n",
    "if train_cols == test_cols:\n",
    "    print(\"✓ Both datasets have the same columns (excluding target)\")\n",
    "else:\n",
    "    print(\"✗ Datasets do NOT have the same columns\")\n",
    "\n",
    "print(f\"\\nComparing data types for {len(common_cols)} common columns:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for col in sorted(common_cols):\n",
    "    train_dtype = df_train[col].dtype\n",
    "    test_dtype = df_test[col].dtype\n",
    "    \n",
    "    if train_dtype == test_dtype:\n",
    "        status = \"✓\"\n",
    "    else:\n",
    "        status = \"✗\"\n",
    "    \n",
    "    print(f\"{status} {col:<35} | Train: {str(train_dtype):<10} | Test: {str(test_dtype)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a4460a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ No null values found in train dataset\n"
     ]
    }
   ],
   "source": [
    "null_counts_train = df_train.isnull().sum()\n",
    "total_nulls_train = null_counts_train.sum()\n",
    "\n",
    "for col in df_train.columns:\n",
    "    null_count = null_counts_train[col]\n",
    "    if null_count > 0:\n",
    "        print(f\"{col:<35} | {null_count:>5} nulls\")\n",
    "\n",
    "if total_nulls_train == 0:\n",
    "    print(\"✓ No null values found in train dataset\")\n",
    "else:\n",
    "    print(f\"\\nTotal null values in train: {total_nulls_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b252a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical features (18):\n",
      "                                      mean    std     min     max\n",
      "age                                  50.36  11.66   19.00   89.00\n",
      "alcohol_consumption_per_week          2.07   1.05    1.00    9.00\n",
      "physical_activity_minutes_per_week   80.23  51.20    1.00  747.00\n",
      "diet_score                            5.96   1.46    0.10    9.90\n",
      "sleep_hours_per_day                   7.00   0.90    3.10    9.90\n",
      "screen_time_hours_per_day             6.01   2.02    0.60   16.50\n",
      "bmi                                  25.87   2.86   15.10   38.40\n",
      "waist_to_hip_ratio                    0.86   0.04    0.68    1.05\n",
      "systolic_bp                         116.29  11.01   91.00  163.00\n",
      "diastolic_bp                         75.44   6.83   51.00  104.00\n",
      "heart_rate                           70.17   6.94   42.00  101.00\n",
      "cholesterol_total                   186.82  16.73  117.00  289.00\n",
      "hdl_cholesterol                      53.82   8.27   21.00   90.00\n",
      "ldl_cholesterol                     102.91  19.02   51.00  205.00\n",
      "triglycerides                       123.08  24.74   31.00  290.00\n",
      "family_history_diabetes               0.15   0.36    0.00    1.00\n",
      "hypertension_history                  0.18   0.39    0.00    1.00\n",
      "cardiovascular_history                0.03   0.17    0.00    1.00\n"
     ]
    }
   ],
   "source": [
    "# Numerical features summary (limited output)\n",
    "numerical_cols = df_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numerical_cols = [col for col in numerical_cols if col not in ['id', 'diagnosed_diabetes']]\n",
    "\n",
    "print(f\"Numerical features ({len(numerical_cols)}):\")\n",
    "print(df_train[numerical_cols].describe().T[['mean', 'std', 'min', 'max']].round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09fb7196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features (6):\n",
      "  gender: 3 unique values\n",
      "  ethnicity: 5 unique values\n",
      "  education_level: 4 unique values\n",
      "  income_level: 5 unique values\n",
      "  smoking_status: 3 unique values\n",
      "  employment_status: 4 unique values\n"
     ]
    }
   ],
   "source": [
    "# Categorical features\n",
    "categorical_cols = df_train.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"Categorical features ({len(categorical_cols)}):\")\n",
    "for col in categorical_cols:\n",
    "    unique_count = df_train[col].nunique()\n",
    "    print(f\"  {col}: {unique_count} unique values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a2db677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top correlations with target:\n",
      "diagnosed_diabetes                    1.000\n",
      "family_history_diabetes               0.211\n",
      "physical_activity_minutes_per_week    0.170\n",
      "age                                   0.161\n",
      "systolic_bp                           0.107\n",
      "bmi                                   0.106\n",
      "ldl_cholesterol                       0.103\n",
      "triglycerides                         0.091\n",
      "cholesterol_total                     0.088\n",
      "waist_to_hip_ratio                    0.081\n",
      "hdl_cholesterol                       0.053\n",
      "Name: diagnosed_diabetes, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Correlation with target (top 10)\n",
    "correlations = df_train[numerical_cols + ['diagnosed_diabetes']].corr()['diagnosed_diabetes'].abs().sort_values(ascending=False)\n",
    "print(\"Top correlations with target:\")\n",
    "print(correlations.head(11).round(3))  # 11 to exclude target itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f014df73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with outliers (>1.5*IQR):\n",
      "  hypertension_history: 127393 (18.2%)\n",
      "  family_history_diabetes: 104581 (14.9%)\n",
      "  physical_activity_minutes_per_week: 33490 (4.8%)\n",
      "  cardiovascular_history: 21227 (3.0%)\n",
      "  triglycerides: 9053 (1.3%)\n",
      "  waist_to_hip_ratio: 6159 (0.9%)\n",
      "  sleep_hours_per_day: 6152 (0.9%)\n",
      "  diastolic_bp: 5752 (0.8%)\n",
      "  hdl_cholesterol: 4693 (0.7%)\n",
      "  bmi: 4254 (0.6%)\n"
     ]
    }
   ],
   "source": [
    "# Check for outliers (IQR method) - only show features with significant outliers\n",
    "outlier_summary = {}\n",
    "for col in numerical_cols:\n",
    "    Q1 = df_train[col].quantile(0.25)\n",
    "    Q3 = df_train[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = ((df_train[col] < lower_bound) | (df_train[col] > upper_bound)).sum()\n",
    "    if outliers > 0:\n",
    "        outlier_summary[col] = outliers\n",
    "\n",
    "if outlier_summary:\n",
    "    print(\"Features with outliers (>1.5*IQR):\")\n",
    "    for col, count in sorted(outlier_summary.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "        pct = (count / len(df_train)) * 100\n",
    "        print(f\"  {col}: {count} ({pct:.1f}%)\")\n",
    "else:\n",
    "    print(\"No significant outliers detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bc5a6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender\n",
      "Other     0.641\n",
      "Male      0.624\n",
      "Female    0.622\n",
      "Name: diagnosed_diabetes, dtype: float64\n",
      "\n",
      "\n",
      "ethnicity\n",
      "Other       0.636\n",
      "Asian       0.628\n",
      "White       0.624\n",
      "Black       0.624\n",
      "Hispanic    0.616\n",
      "Name: diagnosed_diabetes, dtype: float64\n",
      "\n",
      "\n",
      "education_level\n",
      "No formal       0.636\n",
      "Graduate        0.627\n",
      "Highschool      0.621\n",
      "Postgraduate    0.617\n",
      "Name: diagnosed_diabetes, dtype: float64\n",
      "\n",
      "\n",
      "income_level\n",
      "Low             0.630\n",
      "Lower-Middle    0.627\n",
      "High            0.624\n",
      "Upper-Middle    0.620\n",
      "Middle          0.620\n",
      "Name: diagnosed_diabetes, dtype: float64\n",
      "\n",
      "\n",
      "smoking_status\n",
      "Former     0.625\n",
      "Current    0.623\n",
      "Never      0.623\n",
      "Name: diagnosed_diabetes, dtype: float64\n",
      "\n",
      "\n",
      "employment_status\n",
      "Employed      0.625\n",
      "Unemployed    0.622\n",
      "Student       0.622\n",
      "Retired       0.618\n",
      "Name: diagnosed_diabetes, dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Target by categorical features (top categories only)\n",
    "for col in categorical_cols:\n",
    "    target_by_cat = df_train.groupby(col)['diagnosed_diabetes'].mean().sort_values(ascending=False)\n",
    "    print(target_by_cat.head(5).round(3))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f288003",
   "metadata": {},
   "source": [
    "# Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92968348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Education missing: 0 train, 0 test\n",
      "Income missing: 0 train, 0 test\n"
     ]
    }
   ],
   "source": [
    "# Ordinal encoding for variables with natural order\n",
    "education_order = {'No formal': 0, 'Highschool': 1, 'Graduate': 2, 'Postgraduate': 3}\n",
    "income_order = {'Low': 0, 'Lower-Middle': 1, 'Middle': 2, 'Upper-Middle': 3, 'High': 4}\n",
    "\n",
    "df_train['education_level_enc'] = df_train['education_level'].map(education_order)\n",
    "df_train['income_level_enc'] = df_train['income_level'].map(income_order)\n",
    "\n",
    "df_test['education_level_enc'] = df_test['education_level'].map(education_order)\n",
    "df_test['income_level_enc'] = df_test['income_level'].map(income_order)\n",
    "\n",
    "# Verify mappings worked\n",
    "print(f\"Education missing: {df_train['education_level_enc'].isna().sum()} train, {df_test['education_level_enc'].isna().sum()} test\")\n",
    "print(f\"Income missing: {df_train['income_level_enc'].isna().sum()} train, {df_test['income_level_enc'].isna().sum()} test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c23b35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label encoding complete for: ['gender', 'ethnicity', 'smoking_status', 'employment_status']\n"
     ]
    }
   ],
   "source": [
    "# Label encoding for nominal categorical variables (for tree-based models)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "nominal_cols = ['gender', 'ethnicity', 'smoking_status', 'employment_status']\n",
    "label_encoders = {}\n",
    "\n",
    "for col in nominal_cols:\n",
    "    le = LabelEncoder()\n",
    "    # Fit on combined data to ensure consistency\n",
    "    le.fit(pd.concat([df_train[col], df_test[col]]))\n",
    "    df_train[f'{col}_enc'] = le.transform(df_train[col])\n",
    "    df_test[f'{col}_enc'] = le.transform(df_test[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "print(\"Label encoding complete for:\", nominal_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87706971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total features: 24\n",
      "  Numerical: 18\n",
      "  Categorical (encoded): 6\n"
     ]
    }
   ],
   "source": [
    "# Define feature columns for modeling\n",
    "encoded_cat_cols = [f'{col}_enc' for col in categorical_cols]\n",
    "feature_cols = numerical_cols + encoded_cat_cols\n",
    "\n",
    "print(f\"Total features: {len(feature_cols)}\")\n",
    "print(f\"  Numerical: {len(numerical_cols)}\")\n",
    "print(f\"  Categorical (encoded): {len(encoded_cat_cols)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6ec729a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-Hot features added: ['gender_Male', 'gender_Other', 'ethnicity_Black', 'ethnicity_Hispanic', 'ethnicity_Other', 'ethnicity_White', 'smoking_status_Former', 'smoking_status_Never', 'employment_status_Retired', 'employment_status_Student', 'employment_status_Unemployed']\n"
     ]
    }
   ],
   "source": [
    "# One-Hot Encoding for linear models (Logistic Regression, SVM, etc.)\n",
    "# Only for nominal variables (no natural order)\n",
    "nominal_cols = ['gender', 'ethnicity', 'smoking_status', 'employment_status']\n",
    "\n",
    "# Create one-hot encoded features (drop_first=True to avoid multicollinearity)\n",
    "df_train_ohe = pd.get_dummies(df_train[nominal_cols], drop_first=True)\n",
    "df_test_ohe = pd.get_dummies(df_test[nominal_cols], drop_first=True)\n",
    "\n",
    "# Ensure both have same columns\n",
    "missing_in_test = set(df_train_ohe.columns) - set(df_test_ohe.columns)\n",
    "for col in missing_in_test:\n",
    "    df_test_ohe[col] = 0\n",
    "df_test_ohe = df_test_ohe[df_train_ohe.columns]\n",
    "\n",
    "# Add to dataframes\n",
    "df_train = pd.concat([df_train, df_train_ohe], axis=1)\n",
    "df_test = pd.concat([df_test, df_test_ohe], axis=1)\n",
    "\n",
    "print(f\"One-Hot features added: {list(df_train_ohe.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec1167e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features for tree models: 24\n",
      "Features for linear models: 31\n"
     ]
    }
   ],
   "source": [
    "# Feature sets for different model types\n",
    "ohe_cols = list(df_train_ohe.columns)\n",
    "ordinal_cols = ['education_level_enc', 'income_level_enc']\n",
    "\n",
    "# For tree-based models (XGBoost, LightGBM, RandomForest) - can use label encoding\n",
    "features_tree = numerical_cols + encoded_cat_cols\n",
    "\n",
    "# For linear models (Logistic Regression, SVM) - use ordinal + one-hot\n",
    "features_linear = numerical_cols + ordinal_cols + ohe_cols\n",
    "\n",
    "print(f\"Features for tree models: {len(features_tree)}\")\n",
    "print(f\"Features for linear models: {len(features_linear)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a554fa18",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57366e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\carlo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 560,000 samples\n",
      "Val: 140,000 samples\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# Prepare data\n",
    "X = df_train[features_tree]\n",
    "y = df_train['diagnosed_diabetes']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Train: {X_train.shape[0]:,} samples\")\n",
    "print(f\"Val: {X_val.shape[0]:,} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "735dc9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data scaled for linear models\n"
     ]
    }
   ],
   "source": [
    "# Prepare scaled data for linear models\n",
    "X_linear = df_train[features_linear]\n",
    "X_train_lin, X_val_lin, _, _ = train_test_split(X_linear, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_lin)\n",
    "X_val_scaled = scaler.transform(X_val_lin)\n",
    "\n",
    "print(\"Data scaled for linear models\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07e0b083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 0.6644\n",
      "CPU times: total: 1.73 s\n",
      "Wall time: 431 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 1. Logistic Regression\n",
    "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "lr_pred = lr.predict(X_val_scaled)\n",
    "lr_acc = accuracy_score(y_val, lr_pred)\n",
    "print(f\"Logistic Regression: {lr_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df614478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: 0.6650\n",
      "CPU times: total: 3min 2s\n",
      "Wall time: 17.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 2. Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_val)\n",
    "rf_acc = accuracy_score(y_val, rf_pred)\n",
    "print(f\"Random Forest: {rf_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aef2dbfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost (GPU): 0.6745\n",
      "CPU times: total: 4.2 s\n",
      "Wall time: 2.53 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 3. CatBoost (GPU)\n",
    "cat = CatBoostClassifier(\n",
    "    iterations=100, \n",
    "    depth=6, \n",
    "    learning_rate=0.1, \n",
    "    random_seed=42,\n",
    "    task_type='GPU',\n",
    "    devices='0',\n",
    "    verbose=0\n",
    ")\n",
    "cat.fit(X_train, y_train)\n",
    "cat_pred = cat.predict(X_val)\n",
    "cat_acc = accuracy_score(y_val, cat_pred)\n",
    "print(f\"CatBoost (GPU): {cat_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4cea23d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost (GPU): 0.6783\n",
      "CPU times: total: 6.73 s\n",
      "Wall time: 1.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 4. XGBoost (GPU)\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=100, \n",
    "    max_depth=6, \n",
    "    learning_rate=0.1, \n",
    "    random_state=42,\n",
    "    tree_method='hist',\n",
    "    device='cuda',\n",
    "    verbosity=0\n",
    ")\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_pred = xgb.predict(X_val)\n",
    "xgb_acc = accuracy_score(y_val, xgb_pred)\n",
    "print(f\"XGBoost (GPU): {xgb_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d36679e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM (GPU): 0.6794\n",
      "CPU times: total: 12 s\n",
      "Wall time: 2.74 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 5. LightGBM (GPU)\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbm = LGBMClassifier(\n",
    "    n_estimators=100, \n",
    "    max_depth=6, \n",
    "    learning_rate=0.1, \n",
    "    random_state=42, \n",
    "    device='gpu',  # <-- GPU acceleration\n",
    "    verbose=-1\n",
    ")\n",
    "lgbm.fit(X_train, y_train)\n",
    "lgbm_pred = lgbm.predict(X_val)\n",
    "lgbm_acc = accuracy_score(y_val, lgbm_pred)\n",
    "print(f\"LightGBM (GPU): {lgbm_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7cc528c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "MODEL COMPARISON (GPU)\n",
      "========================================\n",
      "              Model  Accuracy\n",
      "           LightGBM  0.679407\n",
      "            XGBoost  0.678307\n",
      "           CatBoost  0.674521\n",
      "      Random Forest  0.664950\n",
      "Logistic Regression  0.664357\n",
      "========================================\n",
      "Best: LightGBM (0.6794)\n"
     ]
    }
   ],
   "source": [
    "# Results comparison\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Random Forest', 'CatBoost', 'XGBoost', 'LightGBM'],\n",
    "    'Accuracy': [lr_acc, rf_acc, cat_acc, xgb_acc, lgbm_acc]\n",
    "}).sort_values('Accuracy', ascending=False)\n",
    "\n",
    "print(\"=\" * 40)\n",
    "print(\"MODEL COMPARISON (GPU)\")\n",
    "print(\"=\" * 40)\n",
    "print(results.to_string(index=False))\n",
    "print(\"=\" * 40)\n",
    "best_model = results.iloc[0]['Model']\n",
    "best_acc = results.iloc[0]['Accuracy']\n",
    "print(f\"Best: {best_model} ({best_acc:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978a23ea",
   "metadata": {},
   "source": [
    "# Continue with XGBoost, LightGBM and CatBoost tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681875d8",
   "metadata": {},
   "source": [
    "# Model Improvement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48098141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports already done in cell 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f68ec4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 35. Best value: 0.682887: 100%|██████████| 50/50 [11:00<00:00, 13.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best XGBoost accuracy (CV-5): 0.6829\n",
      "CPU times: total: 28min 44s\n",
      "Wall time: 11min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Hyperparameter tuning for XGBoost - ANTI-OVERFITTING settings\n",
    "def objective_xgb(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),  # Reducido\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 6),  # Más bajo\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 5, 50),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 0.8), \n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 0.8), \n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.1, 10.0, log=True), \n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.1, 10.0, log=True),\n",
    "        'gamma': trial.suggest_float('gamma', 0.1, 5.0, log=True),\n",
    "        'random_state': 42,\n",
    "        'tree_method': 'hist',\n",
    "        'device': 'cuda',\n",
    "        'verbosity': 0\n",
    "    }\n",
    "    \n",
    "    model = XGBClassifier(**params)\n",
    "    # Usar 5 folds para mejor estimación\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    return scores.mean()\n",
    "\n",
    "study_xgb = optuna.create_study(direction='maximize')\n",
    "study_xgb.optimize(objective_xgb, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "print(f\"Best XGBoost accuracy (CV-5): {study_xgb.best_value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e37e9ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best XGBoost params:\n",
      "  n_estimators: 286\n",
      "  max_depth: 6\n",
      "  learning_rate: 0.0866363069224957\n",
      "  min_child_weight: 18\n",
      "  subsample: 0.6205730028060997\n",
      "  colsample_bytree: 0.6665386903148972\n",
      "  reg_alpha: 0.19458017228568467\n",
      "  reg_lambda: 4.424689982817477\n",
      "  gamma: 3.291700239604379\n"
     ]
    }
   ],
   "source": [
    "# Best XGBoost parameters found\n",
    "print(\"Best XGBoost params:\")\n",
    "for k, v in study_xgb.best_params.items():\n",
    "    print(f\"  {k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f275bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized XGBoost (GPU): 0.6834 (before: 0.6783)\n",
      "Improvement: 0.51%\n",
      "CPU times: total: 8.39 s\n",
      "Wall time: 3.84 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train optimized XGBoost (GPU)\n",
    "xgb_opt = XGBClassifier(**study_xgb.best_params, random_state=42, tree_method='hist', device='cuda', verbosity=0)\n",
    "xgb_opt.fit(X_train, y_train)\n",
    "xgb_opt_pred = xgb_opt.predict(X_val)\n",
    "xgb_opt_acc = accuracy_score(y_val, xgb_opt_pred)\n",
    "\n",
    "print(f\"Optimized XGBoost (GPU): {xgb_opt_acc:.4f} (before: {xgb_acc:.4f})\")\n",
    "print(f\"Improvement: {(xgb_opt_acc - xgb_acc)*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e53c6dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 25. Best value: 0.68383: 100%|██████████| 30/30 [11:28<00:00, 22.95s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LightGBM accuracy (CV): 0.6838\n",
      "CPU times: total: 1h 5min 37s\n",
      "Wall time: 11min 28s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Hyperparameter tuning for LightGBM with Optuna (GPU)\n",
    "def objective_lgbm(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 150),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 10, 100),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "        'random_state': 42,\n",
    "        'device': 'gpu',\n",
    "        'verbose': -1\n",
    "    }\n",
    "    \n",
    "    model = LGBMClassifier(**params)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=3, scoring='accuracy')\n",
    "    return scores.mean()\n",
    "\n",
    "study_lgbm = optuna.create_study(direction='maximize')\n",
    "study_lgbm.optimize(objective_lgbm, n_trials=30, show_progress_bar=True)\n",
    "\n",
    "print(f\"Best LightGBM accuracy (CV): {study_lgbm.best_value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b7a56911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LightGBM params:\n",
      "  n_estimators: 452\n",
      "  max_depth: 7\n",
      "  learning_rate: 0.05919172977770552\n",
      "  num_leaves: 85\n",
      "  min_child_samples: 100\n",
      "  subsample: 0.873262534981045\n",
      "  colsample_bytree: 0.7128524238391454\n",
      "  reg_alpha: 2.5877564601125292e-05\n",
      "  reg_lambda: 0.000556813163881249\n"
     ]
    }
   ],
   "source": [
    "# Best LightGBM parameters found\n",
    "print(\"Best LightGBM params:\")\n",
    "for k, v in study_lgbm.best_params.items():\n",
    "    print(f\"  {k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec95cbaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized LightGBM (GPU): 0.6845 (before: 0.6794)\n",
      "Improvement: 0.51%\n",
      "CPU times: total: 1min 4s\n",
      "Wall time: 11.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train optimized LightGBM (GPU)\n",
    "lgbm_opt = LGBMClassifier(**study_lgbm.best_params, random_state=42, device='gpu', verbose=-1)\n",
    "lgbm_opt.fit(X_train, y_train)\n",
    "lgbm_opt_pred = lgbm_opt.predict(X_val)\n",
    "lgbm_opt_acc = accuracy_score(y_val, lgbm_opt_pred)\n",
    "\n",
    "print(f\"Optimized LightGBM (GPU): {lgbm_opt_acc:.4f} (before: {lgbm_acc:.4f})\")\n",
    "print(f\"Improvement: {(lgbm_opt_acc - lgbm_acc)*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df40aa65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 44. Best value: 0.6799: 100%|██████████| 50/50 [11:59<00:00, 14.38s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CatBoost accuracy (CV-5): 0.6799\n",
      "CPU times: total: 23min 6s\n",
      "Wall time: 11min 59s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# CatBoost tuning - ANTI-OVERFITTING (GPU)\n",
    "def objective_cat(trial):\n",
    "    params = {\n",
    "        'iterations': trial.suggest_int('iterations', 50, 300),\n",
    "        'depth': trial.suggest_int('depth', 2, 6),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1.0, 10.0, log=True),\n",
    "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 1.0),\n",
    "        'random_strength': trial.suggest_float('random_strength', 0.1, 10.0, log=True),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 50, 200),\n",
    "        'random_seed': 42,\n",
    "        'task_type': 'GPU',\n",
    "        'devices': '0',\n",
    "        'verbose': 0\n",
    "    }\n",
    "    \n",
    "    # Manual CV for CatBoost\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = []\n",
    "    for train_idx, val_idx in kf.split(X_train, y_train):\n",
    "        X_tr, X_vl = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_vl = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "        model = CatBoostClassifier(**params)\n",
    "        model.fit(X_tr, y_tr)\n",
    "        scores.append(accuracy_score(y_vl, model.predict(X_vl)))\n",
    "    return np.mean(scores)\n",
    "\n",
    "study_cat = optuna.create_study(direction='maximize')\n",
    "study_cat.optimize(objective_cat, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "print(f\"Best CatBoost accuracy (CV-5): {study_cat.best_value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "93383eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CatBoost params:\n",
      "  iterations: 300\n",
      "  depth: 6\n",
      "  learning_rate: 0.08734589167585863\n",
      "  l2_leaf_reg: 1.405218528590576\n",
      "  bagging_temperature: 0.7309513411152591\n",
      "  random_strength: 0.30503718782412675\n",
      "  min_data_in_leaf: 150\n"
     ]
    }
   ],
   "source": [
    "# Best CatBoost parameters found\n",
    "print(\"Best CatBoost params:\")\n",
    "for k, v in study_cat.best_params.items():\n",
    "    print(f\"  {k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b308d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized CatBoost (GPU): 0.6798 (before: 0.6745)\n",
      "Improvement: 0.53%\n",
      "CPU times: total: 8.48 s\n",
      "Wall time: 4.76 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cat_opt = CatBoostClassifier(**study_cat.best_params, random_seed=42, task_type='GPU', devices='0', verbose=0)\n",
    "cat_opt.fit(X_train, y_train)\n",
    "cat_opt_pred = cat_opt.predict(X_val)\n",
    "cat_opt_acc = accuracy_score(y_val, cat_opt_pred)\n",
    "\n",
    "print(f\"Optimized CatBoost (GPU): {cat_opt_acc:.4f} (before: {cat_acc:.4f})\")\n",
    "print(f\"Improvement: {(cat_opt_acc - cat_acc)*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3aca3165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "FINAL COMPARISON (GPU)\n",
      "==================================================\n",
      "  LightGBM (tuned): 0.6845 ★\n",
      "  XGBoost (tuned): 0.6834\n",
      "  CatBoost (tuned): 0.6798\n",
      "==================================================\n",
      "\n",
      "Best: LightGBM (tuned) (0.6845)\n"
     ]
    }
   ],
   "source": [
    "# Final comparison of all tuned models\n",
    "final_results = pd.DataFrame({\n",
    "    'Model': ['XGBoost (tuned)', 'LightGBM (tuned)', 'CatBoost (tuned)'],\n",
    "    'Accuracy': [xgb_opt_acc, lgbm_opt_acc, cat_opt_acc]\n",
    "}).sort_values('Accuracy', ascending=False)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"FINAL COMPARISON (GPU)\")\n",
    "print(\"=\" * 50)\n",
    "for _, row in final_results.iterrows():\n",
    "    marker = \" ★\" if row['Accuracy'] == final_results['Accuracy'].max() else \"\"\n",
    "    print(f\"  {row['Model']}: {row['Accuracy']:.4f}{marker}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "best_model_name = final_results.iloc[0]['Model']\n",
    "best_acc = final_results.iloc[0]['Accuracy']\n",
    "print(f\"\\nBest: {best_model_name} ({best_acc:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bdaa8753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LightGBM (tuned)\n",
      "Trained on 700,000 samples\n",
      "Predictions: 300,000\n"
     ]
    }
   ],
   "source": [
    "# Kaggle Submission - Train best model on full data\n",
    "X_full = df_train[features_tree]\n",
    "y_full = df_train['diagnosed_diabetes']\n",
    "X_test = df_test[features_tree]\n",
    "\n",
    "# Select and train best model\n",
    "if 'CatBoost' in best_model_name:\n",
    "    final_model = CatBoostClassifier(**study_cat.best_params, random_seed=42, task_type='GPU', devices='0', verbose=0)\n",
    "elif 'LightGBM' in best_model_name:\n",
    "    final_model = LGBMClassifier(**study_lgbm.best_params, random_state=42, device='gpu', verbose=-1)\n",
    "else:\n",
    "    final_model = XGBClassifier(**study_xgb.best_params, random_state=42, tree_method='hist', device='cuda', verbosity=0)\n",
    "\n",
    "final_model.fit(X_full, y_full)\n",
    "test_predictions = final_model.predict(X_test)\n",
    "\n",
    "print(f\"Model: {best_model_name}\")\n",
    "print(f\"Trained on {len(X_full):,} samples\")\n",
    "print(f\"Predictions: {len(test_predictions):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ebd6379a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved to 'submission.csv'\n",
      "Shape: (300000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosed_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>700000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>700001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>700002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>700003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>700004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>700005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>700006</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>700007</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>700008</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>700009</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  diagnosed_diabetes\n",
       "0  700000                   1\n",
       "1  700001                   1\n",
       "2  700002                   1\n",
       "3  700003                   0\n",
       "4  700004                   1\n",
       "5  700005                   1\n",
       "6  700006                   1\n",
       "7  700007                   1\n",
       "8  700008                   1\n",
       "9  700009                   1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create submission file\n",
    "submission = pd.DataFrame({\n",
    "    'id': df_test['id'],\n",
    "    'diagnosed_diabetes': test_predictions.astype(int)\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(f\"Submission saved to 'submission.csv'\")\n",
    "print(f\"Shape: {submission.shape}\")\n",
    "submission.head(10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
